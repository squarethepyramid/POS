POS: Moral Perspectival-Audit Tool (V2.3)

This repository contains the source code for the computational experiments described in the paper "Perspectival Auditing: Testing Structural Invariance of Moral Reasoning in Large Language Models".

The Pos.py script is a research tool designed to audit the structural competence of a Large Language Model (LLM). It tests the model's ability to consistently encode moral scenarios from three distinct ethical perspectives: Utilitarianism, Deontology, and Virtue Ethics.
Prerequisites

    Python 3.8+
    An active API key from Groq

Setup
1. Clone the Repository

First, clone this repository to your local machine using the following command in your terminal:

bash

git clone https://github.com/squarethepyramid/POS

Then, navigate into the newly created folder:

bash

cd POS

2. Install Dependencies

The required Python packages are listed in requirements.txt. It is highly recommended to use a virtual environment. Install the dependencies using pip:

bash

pip install -r requirements.txt

3. Set Your API Key

The script requires a Groq API key to function. This key must be set as an environment variable named GROQ_API_KEY. Do not write your key directly into the Python script.

On macOS / Linux:

bash

export GROQ_API_KEY='your-groq-api-key-here'

On Windows (Command Prompt):

bash

set GROQ_API_KEY=your-groq-api-key-here

How to Run the Audit

The script is executed from the command line.
Basic Usage

You must provide a path to an input CSV file of scenarios and a path for the output results file. The input file must be a CSV with a single column named scenario.

bash

python Pos.py --input path/to/your/scenarios.csv --output path/to/your/results.csv

Optional Arguments

    --model: Specify the model to use for the audit (default: llama3-70b-8192).
    --add-controls: Add a set of control scenarios to the audit.

Example with optional arguments:

bash

python Pos.py --input path/to/scenarios.csv --output path/to/results.csv --model llama3-8b-8192 --add-controls

Data and Reproducibility

The data/ directory contains all the raw data required to reproduce the experiments described in the paper.

    data/input_scenarios/: This folder contains the four CSV files with the scenarios that were used as input to the Pos JAIR.py script.
    data/output_results/: This folder contains the eight raw, unaggregated CSV files generated by the script, representing the outputs for each model and scenario set.

License

This project is licensed under the MIT License. See the LICENSE file for details.
Citation

If you use this tool or the findings from our paper in your research, please cite:

    AUTHOR ONE, AUTHOR TWO, & AUTHOR THREE. (Year). Perspectival Auditing: Testing Structural Invariance of Moral Reasoning in Large Language Models. Journal of Artificial Intelligence Research.
